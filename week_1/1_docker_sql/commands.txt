docker build -t test_pandas_app .

docker run -it --rm --name run_test_pandas test_pandas_app 2022-14-8
    > Output:
        ['pipeline.py', '2022-14-8']
        Pandas imported successfully for 2022-14-8!


# To run Postgresql instance inside Docker:
docker run -it \
        -e POSTGRES_USER="root" \
        -e POSTGRES_PASSWORD="root" \
        -e POSTGRES_DB="ny_taxi" \
        -v c:/Users/Mimo/PycharmProjects/DE_zoomcamp/week_1/1_docker_sql/ny_taxi_postgres_data_volume:/var/lib/postgresql/data \
        -p 5432:5432 \
        postgres:14.5


# To connect to Postgres instance inside Docker, we need pgcli
    pip install pgcli, sqlalchemy
pgcli -h localhost -p 5432 -u root -d ny_taxi

# We also need jupyter notebooks to read the data so:
    pip install pandas
    pip install jupyter
    jupyter notebook


# After downloading and converting the parquet file to csv, since it's too large,
# we'll pipe the output of a 100 rows/columns to a new file to look easily
# kinda like pandas df.head(100):

head -n 100 yellow_tripdata_2021-01.csv > tripdata_100.csv


# To run PGAdmin in Docker:
docker run -it \
    -e PGADMIN_DEFAULT_EMAIL="admin@admin.com" \
    -e PGADMIN_DEFAULT_PASSWORD="root" \
    -p 8080:80 \
    dpage/pgadmin4


# Now PGadmin can't connect to Docker since containers are self hosted
# We need to create a network for that:

docker network create pg-network

# Now the docker run commands need 2 more parameters (--network and --name):
docker run -it \
        -e POSTGRES_USER="root" \
        -e POSTGRES_PASSWORD="root" \
        -e POSTGRES_DB="ny_taxi" \
        -v c:/Users/Mimo/PycharmProjects/DE_zoomcamp/week_1/1_docker_sql/ny_taxi_postgres_data_volume:/var/lib/postgresql/data \
        -p 5432:5432 \
        --network pg-network \
        --name pg-database \
        postgres:14.5

docker run -it \
    -e PGADMIN_DEFAULT_EMAIL="admin@admin.com" \
    -e PGADMIN_DEFAULT_PASSWORD="root" \
    -p 8080:80 \
    --network pg-network \
    --name pgadmin \
    dpage/pgadmin4